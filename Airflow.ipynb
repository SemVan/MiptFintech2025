{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4affdc-7f8b-40f9-a578-3782e9dce2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('scheduler.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "class TaskScheduler:\n",
    "    def __init__(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        \n",
    "    def backup_task(self):\n",
    "        \"\"\"Задача резервного копирования\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Запуск задачи резервного копирования\")\n",
    "            # Ваш код для резервного копирования\n",
    "            time.sleep(2)  # Имитация работы\n",
    "            self.logger.info(\"Резервное копирование завершено\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ошибка в задаче резервного копирования: {e}\")\n",
    "    \n",
    "    def cleanup_task(self):\n",
    "        \"\"\"Задача очистки временных файлов\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Запуск задачи очистки\")\n",
    "            # Ваш код для очистки\n",
    "            time.sleep(1)\n",
    "            self.logger.info(\"Очистка завершена\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ошибка в задаче очистки: {e}\")\n",
    "    \n",
    "    def report_task(self):\n",
    "        \"\"\"Задача генерации отчетов\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Генерация ежедневного отчета\")\n",
    "            # Ваш код для генерации отчета\n",
    "            current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            report_content = f\"Отчет за {current_date}\\nДанные: ...\"\n",
    "            \n",
    "            # Сохранение отчета в файл\n",
    "            report_file = Path(f\"report_{current_date}.txt\")\n",
    "            report_file.write_text(report_content, encoding='utf-8')\n",
    "            \n",
    "            self.logger.info(f\"Отчет сохранен в {report_file}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Ошибка при генерации отчета: {e}\")\n",
    "\n",
    "def main():\n",
    "    scheduler = TaskScheduler()\n",
    "    \n",
    "    # Настройка расписания\n",
    "    schedule.every(3).seconds.do(scheduler.backup_task)\n",
    "    schedule.every().hour.do(scheduler.cleanup_task)\n",
    "    schedule.every().day.at(\"09:00\").do(scheduler.report_task)\n",
    "    schedule.every().day.at(\"18:00\").do(scheduler.report_task)\n",
    "    \n",
    "    logging.info(\"Планировщик задач запущен\")\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"Планировщик остановлен пользователем\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa404eb-bb14-4b53-9722-bbe06f59dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "# Настройки подключения\n",
    "DB_CONFIG = {\n",
    "    'host': 'your_mysql_host',\n",
    "    'user': 'airflow_user',\n",
    "    'password': 'airflow_password',\n",
    "    'database': 'airflow_db',\n",
    "    'cursorclass': pymysql.cursors.DictCursor\n",
    "}\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def generate_db_structure():\n",
    "    conn = pymysql.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # --- 1. SETUP INMON (Source, 3NF) ---\n",
    "    cur.execute(\"DROP TABLE IF EXISTS source_orders\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS source_products\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS source_users\")\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE source_users (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            email VARCHAR(100),\n",
    "            full_name VARCHAR(100),\n",
    "            registration_date DATE,\n",
    "            country VARCHAR(50)\n",
    "        )\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE source_products (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            product_name VARCHAR(100),\n",
    "            category VARCHAR(50),\n",
    "            price DECIMAL(10, 2)\n",
    "        )\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE source_orders (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            user_id INT,\n",
    "            product_id INT,\n",
    "            quantity INT,\n",
    "            order_date DATE,\n",
    "            FOREIGN KEY (user_id) REFERENCES source_users(id),\n",
    "            FOREIGN KEY (product_id) REFERENCES source_products(id)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # --- 2. SETUP KIMBALL (Target, Star Schema) ---\n",
    "    cur.execute(\"DROP TABLE IF EXISTS fact_sales\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS dim_users\")\n",
    "    cur.execute(\"DROP TABLE IF EXISTS dim_products\")\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE dim_users (\n",
    "            user_key INT PRIMARY KEY, -- Skips surrogate key generation for simplicity\n",
    "            user_name VARCHAR(100),\n",
    "            user_country VARCHAR(50)\n",
    "        )\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE dim_products (\n",
    "            product_key INT PRIMARY KEY,\n",
    "            product_name VARCHAR(100),\n",
    "            product_category VARCHAR(50),\n",
    "            current_price DECIMAL(10, 2)\n",
    "        )\n",
    "    \"\"\")\n",
    "    cur.execute(\"\"\"\n",
    "        CREATE TABLE fact_sales (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            user_key INT,\n",
    "            product_key INT,\n",
    "            total_amount DECIMAL(10, 2),\n",
    "            sale_date DATE,\n",
    "            data_load_ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    # --- 3. SEED DATA ---\n",
    "    print(\"Generating Users...\")\n",
    "    users = [(fake.email(), fake.name(), fake.date_between(start_date='-2y', end_date='today'), fake.country()) for _ in range(100)]\n",
    "    cur.executemany(\"INSERT INTO source_users (email, full_name, registration_date, country) VALUES (%s, %s, %s, %s)\", users)\n",
    "    \n",
    "    print(\"Generating Products...\")\n",
    "    products = [(fake.word(), fake.word(), random.uniform(10, 500)) for _ in range(50)]\n",
    "    cur.executemany(\"INSERT INTO source_products (product_name, category, price) VALUES (%s, %s, %s)\", products)\n",
    "    \n",
    "    conn.commit()\n",
    "\n",
    "    print(\"Generating Orders...\")\n",
    "    # Get IDs\n",
    "    cur.execute(\"SELECT id FROM source_users\")\n",
    "    u_ids = [row['id'] for row in cur.fetchall()]\n",
    "    cur.execute(\"SELECT id FROM source_products\")\n",
    "    p_ids = [row['id'] for row in cur.fetchall()]\n",
    "\n",
    "    orders = []\n",
    "    for _ in range(1000):\n",
    "        orders.append((\n",
    "            random.choice(u_ids),\n",
    "            random.choice(p_ids),\n",
    "            random.randint(1, 5),\n",
    "            fake.date_between(start_date='-1y', end_date='today')\n",
    "        ))\n",
    "    cur.executemany(\"INSERT INTO source_orders (user_id, product_id, quantity, order_date) VALUES (%s, %s, %s, %s)\", orders)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(\"Database Initialized!\")\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_db_structure()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210a3f1-3aa7-4a28-afdf-fedae4d0005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.providers.mysql.hooks.mysql import MySqlHook\n",
    "from datetime import datetime\n",
    "\n",
    "# Стандартный аргументы\n",
    "default_args = {\n",
    "    'owner': 'student',\n",
    "    'start_date': datetime(2023, 1, 1),\n",
    "    'retries': 1,\n",
    "}\n",
    "\n",
    "def etl_users_process():\n",
    "    # Hook - это абстракция Airflow над коннекшном.\n",
    "    # Он берет креды из Admin -> Connections (conn_id='mysql_default')\n",
    "    hook = MySqlHook(mysql_conn_id='mysql_default')\n",
    "    conn = hook.get_conn()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 1. Extract (из Inmon)\n",
    "    cursor.execute(\"SELECT id, full_name, country FROM source_users\")\n",
    "    users = cursor.fetchall()\n",
    "\n",
    "    # 2. Transform (Примитивная)\n",
    "    transformed_users = []\n",
    "    for u in users:\n",
    "        # Пример: приведение к верхнему регистру\n",
    "        transformed_users.append((u[0], u[1].upper(), u[2]))\n",
    "\n",
    "    # 3. Load (в Kimball)\n",
    "    # ВАЖНО: Идемпотентность! Сначала чистим, потом пишем, или используем UPSERT.\n",
    "    # Для простоты примера делаем Full Reload\n",
    "    cursor.execute(\"TRUNCATE TABLE dim_users\") \n",
    "    cursor.executemany(\n",
    "        \"INSERT INTO dim_users (user_key, user_name, user_country) VALUES (%s, %s, %s)\", \n",
    "        transformed_users\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def etl_fact_sales_process(**context):\n",
    "    # Доступ к дате исполнения DAG-а\n",
    "    execution_date = context['ds'] \n",
    "    \n",
    "    hook = MySqlHook(mysql_conn_id='mysql_default')\n",
    "    conn = hook.get_conn()\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Собираем данные: Join в источнике (ELT подход часто лучше чистого ETL)\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT \n",
    "            o.user_id, \n",
    "            o.product_id, \n",
    "            (o.quantity * p.price) as total,\n",
    "            o.order_date\n",
    "        FROM source_orders o\n",
    "        JOIN source_products p ON o.product_id = p.id\n",
    "        WHERE o.order_date = '{execution_date}' \n",
    "    \"\"\"\n",
    "    cursor.execute(sql_query)\n",
    "    sales = cursor.fetchall()\n",
    "\n",
    "    if sales:\n",
    "        # Удаляем данные за эту дату, чтобы избежать дублей при перезапуске\n",
    "        cursor.execute(f\"DELETE FROM fact_sales WHERE sale_date = '{execution_date}'\")\n",
    "        \n",
    "        cursor.executemany(\n",
    "            \"INSERT INTO fact_sales (user_key, product_key, total_amount, sale_date) VALUES (%s, %s, %s, %s)\",\n",
    "            sales\n",
    "        )\n",
    "        conn.commit()\n",
    "        print(f\"Loaded {len(sales)} rows for {execution_date}\")\n",
    "    else:\n",
    "        print(f\"No sales for {execution_date}\")\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "with DAG('01_classic_etl', default_args=default_args, schedule_interval='@daily', catchup=False) as dag:\n",
    "    \n",
    "    t1_dim_users = PythonOperator(\n",
    "        task_id='load_dim_users',\n",
    "        python_callable=etl_users_process\n",
    "    )\n",
    "\n",
    "    t2_fact_sales = PythonOperator(\n",
    "        task_id='load_fact_sales',\n",
    "        python_callable=etl_fact_sales_process,\n",
    "        provide_context=True # Нужно, чтобы передать context (дату) в функцию\n",
    "    )\n",
    "\n",
    "    t1_dim_users >> t2_fact_sales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e207ce-84e8-4a4c-a2c9-1e491a7e526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import dag, task\n",
    "from airflow.operators.python import BranchPythonOperator\n",
    "from airflow.providers.mysql.hooks.mysql import MySqlHook\n",
    "from datetime import datetime\n",
    "\n",
    "@dag(schedule_interval='@daily', start_date=datetime(2023, 1, 1), catchup=False, tags=['seminar'])\n",
    "def modern_etl_dag():\n",
    "\n",
    "    @task()\n",
    "    def extract_high_value_sales(ds=None):\n",
    "        \"\"\"Извлекаем заказы дороже 1000 у.е.\"\"\"\n",
    "        hook = MySqlHook(mysql_conn_id='mysql_default')\n",
    "        # Используем pandas для удобства (частый кейс в Airflow)\n",
    "        df = hook.get_pandas_df(sql=f\"\"\"\n",
    "            SELECT o.id, (o.quantity * p.price) as total \n",
    "            FROM source_orders o\n",
    "            JOIN source_products p ON o.product_id = p.id\n",
    "            WHERE o.order_date = '{ds}'\n",
    "        \"\"\")\n",
    "        # Возвращаем словарь или список словарей (автоматически сериализуется в XCom)\n",
    "        return df.to_dict('records')\n",
    "\n",
    "    @task()\n",
    "    def check_revenue(sales_data):\n",
    "        \"\"\"Принимаем данные из предыдущей задачи через аргумент\"\"\"\n",
    "        total_revenue = sum([s['total'] for s in sales_data])\n",
    "        print(f\"Total revenue today: {total_revenue}\")\n",
    "        \n",
    "        # Логика ветвления\n",
    "        if total_revenue > 5000:\n",
    "            return 'notify_manager'\n",
    "        return 'skip_notification'\n",
    "\n",
    "    # Старый добрый оператор для ветвления (он пока не имеет декоратора во всех версиях)\n",
    "    branching = BranchPythonOperator(\n",
    "        task_id='branching',\n",
    "        python_callable=lambda ti: ti.xcom_pull(task_ids='check_revenue')\n",
    "    )\n",
    "\n",
    "    @task(task_id='notify_manager')\n",
    "    def send_alert():\n",
    "        print(\"ALERT: Huge revenue today! Champagne time!\")\n",
    "\n",
    "    @task(task_id='skip_notification')\n",
    "    def relax():\n",
    "        print(\"Just a normal day.\")\n",
    "\n",
    "    # Строим зависимости\n",
    "    sales = extract_high_value_sales()\n",
    "    decision = check_revenue(sales)\n",
    "    \n",
    "    decision >> branching >> [send_alert(), relax()]\n",
    "\n",
    "dag = modern_etl_dag()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a637c-b522-44da-b236-7518d07d7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "from airflow.operators.empty import EmptyOperator\n",
    "from datetime import datetime\n",
    "\n",
    "# Конфиг: список таблиц для репликации\n",
    "TABLES_TO_SYNC = ['users', 'products', 'orders']\n",
    "\n",
    "def create_dag(table_name):\n",
    "    \"\"\"Фабрика дагов\"\"\"\n",
    "    dag_id = f'sync_table_{table_name}'\n",
    "    \n",
    "    default_args = {'owner': 'dynamic', 'start_date': datetime(2023, 1, 1)}\n",
    "    \n",
    "    dag = DAG(dag_id, default_args=default_args, schedule_interval='@daily', catchup=False)\n",
    "    \n",
    "    with dag:\n",
    "        start = EmptyOperator(task_id='start')\n",
    "        \n",
    "        process = PythonOperator(\n",
    "            task_id=f'process_{table_name}',\n",
    "            python_callable=lambda: print(f\"Mirroring table: {table_name} from Source to DWH...\")\n",
    "        )\n",
    "        \n",
    "        end = EmptyOperator(task_id='end')\n",
    "        \n",
    "        start >> process >> end\n",
    "        \n",
    "    return dag\n",
    "\n",
    "# Генерируем объекты DAG в глобальной области видимости\n",
    "for table in TABLES_TO_SYNC:\n",
    "    dag_object = create_dag(table)\n",
    "    globals()[dag_object.dag_id] = dag_object\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
